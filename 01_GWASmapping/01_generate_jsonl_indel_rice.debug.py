#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä»VCFæ ¼å¼ç”Ÿæˆæ ·æœ¬ä¸€è‡´æ€§åºåˆ—
æ”¯æŒSNPã€Indel(æ’å…¥/ç¼ºå¤±)ã€å¤šç­‰ä½å˜å¼‚ã€DELæ ‡è®°
"""

import os
import json
import numpy as np
import pandas as pd
import pysam
from cyvcf2 import VCF
from tqdm import tqdm
import argparse

def parse_args():
    parser = argparse.ArgumentParser(
        description="ä»VCFç”Ÿæˆblockçº§æ ·æœ¬ä¸€è‡´æ€§åºåˆ—(JSON)"
    )

    parser.add_argument(
        "--bed",
        required=True,
        help="BED æ–‡ä»¶ï¼ˆblock/window åŒºé—´ï¼‰"
    )
    parser.add_argument(
        "--pheno",
        required=True,
        help="è¡¨å‹æ–‡ä»¶ï¼ˆå¿…é¡»åŒ…å« SampleID åˆ—ï¼‰"
    )
    parser.add_argument(
        "--vcf",
        required=True,
        help="VCF/VCF.GZ/BCF æ–‡ä»¶"
    )
    parser.add_argument(
        "--fasta",
        required=True,
        help="å‚è€ƒåŸºå› ç»„ FASTA(.fa/.fna/.gz)"
    )
    parser.add_argument(
        "--pheno-col",
        required=True,
        help="è¡¨å‹åˆ—åï¼Œä¾‹å¦‚ Trait"
    )
    parser.add_argument(
        "--out",
        default="json_blocks",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: json_blocksï¼‰"
    )

    return parser.parse_args()

# =====================
# å‚æ•°è¯»å–
# =====================
args = parse_args()

bed_file = args.bed
pheno_file = args.pheno
vcf_file = args.vcf
fasta_file = args.fasta
target_pheno_col = args.pheno_col
out_dir = args.out

os.makedirs(out_dir, exist_ok=True)

# =====================
# æŸ“è‰²ä½“æ˜ å°„
# =====================
chrom_map = {
    '1': '1', '2': '2', '3': '3',
    '4': '4', '5': '5', '6': '6',
    '7': '7', '8': '8', '9': '9',
    '10': '10', '11': '11', '12': '12'
}

# åå‘æ˜ å°„ï¼šä»FASTAæŸ“è‰²ä½“ååˆ°ç®€åŒ–å
chrom_map_reverse = {v: k for k, v in chrom_map.items()}

# =====================
# 1. è¯»å–è¡¨å‹
# =====================
print("â¡ï¸ è¯»å–è¡¨å‹æ•°æ® ...")
pheno = pd.read_csv(pheno_file, sep="\t")
pheno = pheno.dropna(subset=[target_pheno_col])
pheno = pheno.set_index("SampleID")
print(f"âœ… æœ‰æ•ˆè¡¨å‹æ ·æœ¬æ•°: {len(pheno)}")

# =====================
# 2. è¯»å–BEDåŒºé—´
# =====================
print("â¡ï¸ è¯»å–BEDæ–‡ä»¶ ...")
bed_df = pd.read_csv(bed_file, sep="\t", header=None, names=["chrom", "start", "end"])
print(f"âœ… BED åŒºé—´æ•°: {len(bed_df)}")

# =====================
# 3. è¯»å–FASTAå‚è€ƒåºåˆ—
# =====================
print("â¡ï¸ æ‰“å¼€FASTAæ–‡ä»¶ ...")
fasta = pysam.FastaFile(fasta_file)

# =====================
# 4. è¯»å–VCFæ–‡ä»¶
# =====================
print("â¡ï¸ è¯»å–VCFæ–‡ä»¶ ...")
vcf = VCF(vcf_file)
vcf_samples = vcf.samples
print(f"âœ… VCFæ ·æœ¬æ•°: {len(vcf_samples)}")
print(f"  ç¤ºä¾‹æ ·æœ¬: {vcf_samples[:5]}")

# =====================
# 5. æ ·æœ¬è¿‡æ»¤å’Œæ˜ å°„
# =====================
# æ‰¾åˆ°æ—¢åœ¨è¡¨å‹ä¸­åˆåœ¨VCFä¸­çš„æ ·æœ¬
pheno_samples = [s for s in pheno.index if s in vcf_samples]
sample_to_idx = {sid: i for i, sid in enumerate(vcf_samples)}
pheno_idx = [sample_to_idx[s] for s in pheno_samples]
labels = pheno.loc[pheno_samples, target_pheno_col].values

print(f"âœ… å…±åŒæ ·æœ¬æ•°: {len(pheno_samples)}")
print(f"ç¤ºä¾‹æ ·æœ¬: {pheno_samples[:5]}")

# =====================
# 6. è¾…åŠ©å‡½æ•°
# =====================
def classify_variant(ref, alt):
    """
    åˆ¤æ–­å˜å¼‚ç±»å‹
    è¿”å›: 'SNP', 'INS' (insertion), 'DEL' (deletion), 'COMPLEX'
    """
    ref = str(ref).upper()
    alt = str(alt).upper()

    len_ref = len(ref)
    len_alt = len(alt)

    if len_ref == 1 and len_alt == 1:
        return 'SNP'
    elif len_ref < len_alt:
        return 'INS'  # æ’å…¥
    elif len_ref > len_alt:
        return 'DEL'  # ç¼ºå¤±
    else:
        return 'COMPLEX'


def apply_variant_to_sequence(ref_seq, variant_list):
    """
    å°†å˜å¼‚åº”ç”¨åˆ°å‚è€ƒåºåˆ—

    å‚æ•°:
        ref_seq: å‚è€ƒåºåˆ—(å­—ç¬¦ä¸²)
        variant_list: [(offset, variant_type, ref, alt), ...]
                     offset: ç›¸å¯¹äºref_seqèµ·å§‹çš„ä½ç½®(0-based)

    è¿”å›:
        ä¿®æ”¹åçš„åºåˆ—(å­—ç¬¦ä¸²)
    """
    # æŒ‰ä½ç½®ä»åå¾€å‰æ’åº,é¿å…æ’å…¥/åˆ é™¤å½±å“åç»­ä½ç½®
    variant_list = sorted(variant_list, key=lambda x: x[0], reverse=True)

    seq = list(ref_seq)

    for offset, var_type, ref, alt in variant_list:
        if offset < 0 or offset >= len(seq):
            continue

        if var_type == 'SNP':
            # ç®€å•æ›¿æ¢
            seq[offset] = alt

        elif var_type == 'INS':
            # æ’å…¥: åœ¨offsetä½ç½®åæ’å…¥é¢å¤–ç¢±åŸº
            seq[offset] = alt[0]
            insert_bases = alt[1:]
            for i, base in enumerate(insert_bases):
                seq.insert(offset + 1 + i, base)

        elif var_type == 'DEL':
            # ç¼ºå¤±: æ›¿æ¢ä¸ºN
            seq[offset] = alt[0] if len(alt) > 0 else 'N'
            for i in range(1, len(ref)):
                if offset + i < len(seq):
                    seq[offset + i] = 'N'

        elif var_type == 'COMPLEX':
            # å¤æ‚å˜å¼‚: ç®€å•å¤„ç†ä¸ºæ›¿æ¢+å¡«å……N
            seq[offset] = alt[0] if len(alt) > 0 else 'N'
            if len(ref) > 1:
                for i in range(1, len(ref)):
                    if offset + i < len(seq):
                        seq[offset + i] = 'N'

    return ''.join(seq)


# =====================
# 7. ä¸»å¾ªç¯: é€blockå¤„ç†
# =====================
print("\n" + "="*60)
print("å¼€å§‹å¤„ç†blocks...")
print("="*60)

for block_id, row in tqdm(bed_df.iterrows(), total=len(bed_df), desc="Processing blocks"):
    chrom = str(row['chrom'])
    start = int(row['start'])
    end = int(row['end'])
    block_name = f"block_{block_id+1}"

    # è·³è¿‡ä¸åœ¨æ˜ å°„è¡¨ä¸­çš„æŸ“è‰²ä½“
    if chrom not in chrom_map:
        print(f"âš ï¸  è·³è¿‡ {block_name}: æŸ“è‰²ä½“ {chrom} ä¸åœ¨æ˜ å°„è¡¨ä¸­")
        continue

    # æå–å‚è€ƒåºåˆ—
    try:
        ref_seq = fasta.fetch(chrom_map[chrom], start, end).upper()
    except Exception as e:
        print(f"âš ï¸  è·³è¿‡ {block_name}: FASTAæå–å¤±è´¥ - {e}")
        continue

    print(f"\nğŸ“ {block_name}: æŸ“è‰²ä½“{chrom}:{start}-{end}")

    # è¯»å–è¯¥åŒºé—´çš„æ‰€æœ‰å˜å¼‚
    variants_in_block = []
    
    # VCFæŸ“è‰²ä½“åå¯èƒ½æ˜¯"4"æˆ–"AP014960.1"ï¼Œéƒ½è¯•ä¸€ä¸‹
    vcf_chrom_names = [chrom, chrom_map.get(chrom, chrom)]
    
    for vcf_chrom in vcf_chrom_names:
        try:
            for variant in vcf(f"{vcf_chrom}:{start}-{end}"):
                variants_in_block.append(variant)
            if len(variants_in_block) > 0:
                break  # æ‰¾åˆ°å˜å¼‚å°±åœæ­¢
        except Exception as e:
            continue
    
    if len(variants_in_block) == 0:
        print(f"âš ï¸  è·³è¿‡ {block_name}: æ— å˜å¼‚")
        continue

    print(f"  å˜å¼‚æ•°: {len(variants_in_block)}")

    # é€æ ·æœ¬ç”Ÿæˆåºåˆ—
    json_list = []

    for i, sample in enumerate(tqdm(pheno_samples, desc=f"  {block_name} æ ·æœ¬", leave=False)):
        sample_idx = pheno_idx[i]
        sample_variants = []

        for variant in variants_in_block:
            # è·å–è¯¥æ ·æœ¬çš„åŸºå› å‹
            gt = variant.genotypes[sample_idx]
            
            # gtæ˜¯ä¸€ä¸ªåˆ—è¡¨: [allele1, allele2, phased]
            # allele: 0=REF, 1=ç¬¬1ä¸ªALT, 2=ç¬¬2ä¸ªALT, -1=ç¼ºå¤±
            allele1, allele2, phased = gt[0], gt[1], gt[2]
            
            # ğŸ”¥ è°ƒè¯•ï¼šåªçœ‹å‰5ä¸ªæ ·æœ¬
            if i < 10:
                print(f"\næ ·æœ¬ {sample} (ç´¢å¼•{i}):")
                print(f"  ä½ç½®: {variant.POS}")
                print(f"  åŸºå› å‹: {allele1}/{allele2}")
                print(f"  REF: {variant.REF}, ALT: {variant.ALT}")
                print(f"  BED: {start}-{end}, å‚è€ƒåºåˆ—é•¿åº¦: {len(ref_seq)}")
            
            # å¤„ç†ç¼ºå¤±åŸºå› å‹
            if allele1 == -1 or allele2 == -1:
                applied_allele = 'N' * len(variant.REF)
                var_type = 'COMPLEX'
                offset = variant.POS - start - 1
                sample_variants.append((offset, var_type, variant.REF, applied_allele))
                if i < 10:
                    print(f"  â†’ ç¼ºå¤±åŸºå› å‹ï¼Œæ·»åŠ : offset={offset}, type={var_type}")
                continue
            
            # çº¯åˆå‚è€ƒå‹ (0/0)
            elif allele1 == 0 and allele2 == 0:
                if i < 10:
                    print(f"  â†’ çº¯åˆå‚è€ƒå‹ï¼Œè·³è¿‡")
                continue  # ä¸ä¿®æ”¹å‚è€ƒåºåˆ—
            
            # å…¶ä»–æƒ…å†µï¼šä½¿ç”¨ç­‰ä½åŸºå› 
            else:
                if i < 10:
                    print(f"  â†’ éå‚è€ƒåŸºå› å‹ï¼Œå¼€å§‹å¤„ç†...")
                
                # å¯¹äºæ‚åˆå­ï¼Œé€‰æ‹©éå‚è€ƒç­‰ä½åŸºå› 
                # å¯¹äºçº¯åˆå­ï¼Œä½¿ç”¨è¯¥ç­‰ä½åŸºå› 
                if allele1 == 0:
                    allele_idx = allele2  # 0/1 -> ä½¿ç”¨ALT1
                elif allele2 == 0:
                    allele_idx = allele1  # 1/0 -> ä½¿ç”¨ALT1
                else:
                    # ä¸¤ä¸ªéƒ½æ˜¯ALTï¼Œä¼˜å…ˆä½¿ç”¨è¾ƒå¤§çš„ï¼ˆæ›´åé¢çš„ALTï¼‰
                    allele_idx = max(allele1, allele2)
                
                if i < 10:
                    print(f"  é€‰æ‹©ç­‰ä½åŸºå› ç´¢å¼•: {allele_idx}")
                
                # è·å–å¯¹åº”çš„ALTåºåˆ—
                if allele_idx == 0:
                    if i < 10:
                        print(f"  â†’ ç­‰ä½åŸºå› ç´¢å¼•ä¸º0ï¼Œè·³è¿‡")
                    continue  # å‚è€ƒç­‰ä½åŸºå› ï¼ˆä¸åº”è¯¥åˆ°è¿™é‡Œï¼‰
                else:
                    # allele_idx-1 å¯¹åº”åˆ°ALTåˆ—è¡¨çš„ç´¢å¼•
                    # ä¾‹å¦‚ï¼šallele_idx=1 å¯¹åº” ALT[0]ï¼Œallele_idx=2 å¯¹åº” ALT[1]
                    alt_list = variant.ALT
                    alt_index = allele_idx - 1
                    
                    if i < 10:
                        print(f"  ALTåˆ—è¡¨: {alt_list}, alt_index={alt_index}")
                    
                    if alt_index < len(alt_list):
                        applied_allele = alt_list[alt_index]
                        
                        if i < 10:
                            print(f"  è·å–åˆ°applied_allele: {applied_allele}")
                        
                        # ğŸ”¥ å…³é”®ï¼šå¤„ç†DELæ ‡è®°ï¼ˆå¯èƒ½æ˜¯ "DEL", "<DEL>", "*" ç­‰ï¼‰
                        if applied_allele in ['DEL', '<DEL>', '*', '.']:
                            # DELè¡¨ç¤ºè¯¥ä½ç½®å®Œå…¨ç¼ºå¤±ï¼Œç”¨Nå¡«å……REFé•¿åº¦
                            applied_allele = 'N' * len(variant.REF)
                            var_type = 'DEL'
                            if i < 10:
                                print(f"  â†’ DELæ ‡è®°ï¼Œè½¬æ¢ä¸ºN")
                        else:
                            # æ­£å¸¸å˜å¼‚ï¼Œåˆ¤æ–­ç±»å‹
                            var_type = classify_variant(variant.REF, applied_allele)
                            if i < 10:
                                print(f"  â†’ æ­£å¸¸å˜å¼‚ï¼Œç±»å‹: {var_type}")
                    else:
                        # ç´¢å¼•è¶Šç•Œï¼Œæ ‡è®°ä¸ºç¼ºå¤±
                        applied_allele = 'N' * len(variant.REF)
                        var_type = 'COMPLEX'
                        offset = variant.POS - start - 1
                        sample_variants.append((offset, var_type, variant.REF, applied_allele))
                        if i < 10:
                            print(f"  â†’ ç´¢å¼•è¶Šç•Œï¼Œæ·»åŠ : offset={offset}, type={var_type}")
                        continue

            # è®¡ç®—ç›¸å¯¹å‚è€ƒåºåˆ—çš„offset (0-based)
            # VCFçš„POSæ˜¯1-based
            offset = variant.POS - start - 1

            if i < 10:
                print(f"  è®¡ç®—offset: {variant.POS} - {start} - 1 = {offset}")
                print(f"  æ·»åŠ åˆ°sample_variants: offset={offset}, type={var_type}, ref={variant.REF}, alt={applied_allele}")

            sample_variants.append((offset, var_type, variant.REF, applied_allele))

        # ğŸ”¥ åº”ç”¨å˜å¼‚å‰åå¯¹æ¯”
        if i < 10:
            print(f"\næ ·æœ¬ {sample} åº”ç”¨å˜å¼‚:")
            print(f"  sample_variants æ•°é‡: {len(sample_variants)}")
            if len(sample_variants) > 0:
                for sv in sample_variants:
                    offset_sv = sv[0]
                    print(f"  å˜å¼‚ offset={offset_sv}: åŸå§‹ref_seq[{offset_sv}]={ref_seq[offset_sv] if offset_sv < len(ref_seq) else 'è¶Šç•Œ'}")
        
        # åº”ç”¨æ‰€æœ‰å˜å¼‚åˆ°å‚è€ƒåºåˆ—
        consensus_seq = apply_variant_to_sequence(ref_seq, sample_variants)

        if i < 10:
            if len(sample_variants) > 0:
                for sv in sample_variants:
                    offset_sv = sv[0]
                    print(f"  å˜å¼‚ offset={offset_sv}: æ›¿æ¢åconsensus_seq[{offset_sv}]={consensus_seq[offset_sv] if offset_sv < len(consensus_seq) else 'è¶Šç•Œ'}")

        json_list.append({
            "label": int(labels[i]),
            "spec": sample,
            "loc": block_name,
            "sequence": consensus_seq
        })

    # è¾“å‡ºJSON
    out_path = os.path.join(out_dir, f"{block_name}.json")
    with open(out_path, "w") as f:
        json.dump(json_list, f, indent=2)

    print(f"âœ… {block_name} å®Œæˆ | å˜å¼‚æ•°={len(variants_in_block)} | æ ·æœ¬æ•°={len(pheno_samples)}")

# =====================
# 8. æ¸…ç†
# =====================
fasta.close()
vcf.close()

print("\n" + "="*60)
print("ğŸ‰ å…¨éƒ¨å®Œæˆ!")
print(f"è¾“å‡ºç›®å½•: {out_dir}")
print("="*60)
